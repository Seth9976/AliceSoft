// 函数: sub_701310
// 地址: 0x701310
// 来自: E:\torrent\AliceSoft\ランス01\Rance01.exe

void* edx = arg1
void* esp

if ((edx & 0xf) != 0)
    void var_80
    esp = &var_80
    edx = &var_80

if ((arg1 & 0xf) != 0)
    int32_t xmm0_41[0x4] = arg1[1]
    int32_t xmm1_46[0x4] = arg1[6]
    int32_t xmm3_18[0x4] = arg1[2]
    int32_t xmm0_42[0x4] = _mm_adds_epi16(xmm0_41, xmm1_46)
    int32_t xmm4_34[0x4] = arg1[5]
    uint16_t xmm0_43[0x8] = _mm_slli_epi16(xmm0_42, 3)
    int32_t xmm5_37[0x4] = *arg1
    int32_t xmm4_35[0x4] = _mm_adds_epi16(xmm4_34, xmm3_18)
    int32_t xmm5_38[0x4] = _mm_adds_epi16(xmm5_37, arg1[7])
    int32_t xmm2_19[0x4] = _mm_subs_epi16(xmm0_41, xmm1_46)
    int16_t xmm1_47[0x8] = *"\nj\nj\nj\nj\nj\nj\nj\nj"
    int32_t xmm4_36[0x4] = _mm_slli_epi16(xmm4_35, 3)
    int32_t xmm0_44[0x4] = _mm_subs_epi16(xmm0_43, xmm4_36)
    int32_t xmm7_17[0x4] = arg1[3]
    int32_t xmm6_18[0x4] = _mm_adds_epi16(xmm0_43, xmm4_36)
    int32_t xmm7_18[0x4] = _mm_adds_epi16(xmm7_17, arg1[4])
    int16_t xmm1_48[0x8] = _mm_mulhi_epi16(xmm1_47, xmm0_44)
    int32_t xmm5_39[0x4] = _mm_subs_epi16(xmm5_38, xmm7_18)
    int32_t xmm4_39[0x4] = _mm_adds_epi16(xmm5_38, xmm7_18)
    int32_t xmm5_40[0x4] = _mm_slli_epi16(xmm5_39, 3)
    int32_t xmm1_49[0x4] = _mm_adds_epi16(xmm1_48, xmm5_40)
    uint16_t xmm4_40[0x8] = _mm_slli_epi16(xmm4_39, 3)
    uint16_t xmm1_50[0x8] = xmm1_49 | data_78d6b0.o
    uint16_t xmm2_20[0x8] = _mm_slli_epi16(xmm2_19, 4)
    int16_t xmm5_41[0x8] = __pmulhw_xmmdq_memdq(xmm5_40, *"\nj\nj\nj\nj\nj\nj\nj\nj")
    *(edx + 0x20) = _mm_shufflehi_epi16(xmm1_50, 0x1b)
    int32_t xmm4_41[0x4] = _mm_subs_epi16(xmm4_40, xmm6_18)
    int32_t xmm3_19[0x4] = _mm_subs_epi16(xmm3_18, arg1[5])
    int32_t xmm7_20[0x4] = _mm_adds_epi16(xmm4_40, xmm6_18)
    int32_t xmm1_53[0x4] = arg1[3]
    int32_t xmm3_20[0x4] = _mm_slli_epi16(xmm3_19, 4)
    int32_t xmm1_54[0x4] = _mm_subs_epi16(xmm1_53, arg1[4])
    *(edx + 0x40) = _mm_shufflehi_epi16(xmm4_41, 0x1b)
    int16_t xmm2_22[0x8] = __pmulhw_xmmdq_memdq(_mm_adds_epi16(xmm2_20, xmm3_20), data_78d710.o)
    int16_t xmm6_22[0x8] = __pmulhw_xmmdq_memdq(_mm_subs_epi16(xmm2_20, xmm3_20), data_78d710.o)
    uint16_t xmm5_43[0x8] = _mm_subs_epi16(xmm5_41, xmm0_44) | data_78d6b0.o
    uint16_t xmm1_55[0x8] = _mm_slli_epi16(xmm1_54, 3)
    int32_t xmm2_23[0x4] = xmm2_22 | data_78d6b0.o
    int32_t xmm3_21[0x4] = *arg1
    int32_t xmm1_56[0x4] = _mm_adds_epi16(xmm1_55, xmm6_22)
    int32_t xmm3_22[0x4] = _mm_subs_epi16(xmm3_21, arg1[7])
    int32_t xmm4_44[0x4] = _mm_subs_epi16(xmm1_55, xmm6_22)
    int16_t xmm0_46[0x8] = data_78d6d0.o
    uint16_t xmm3_23[0x8] = _mm_slli_epi16(xmm3_22, 3)
    int16_t xmm6_23[0x8] = data_78d6f0.o
    int16_t xmm0_47[0x8] = _mm_mulhi_epi16(xmm0_46, xmm1_56)
    *edx = _mm_shufflehi_epi16(xmm7_20, 0x1b)
    int16_t xmm6_24[0x8] = _mm_mulhi_epi16(xmm6_23, xmm4_44)
    *(edx + 0x60) = _mm_shufflehi_epi16(xmm5_43, 0x1b)
    int16_t xmm5_45[0x8] = data_78d6f0.o
    int32_t xmm7_23[0x4] = _mm_subs_epi16(xmm3_23, xmm2_23)
    int32_t xmm3_24[0x4] = _mm_adds_epi16(xmm3_23, xmm2_23)
    int16_t xmm5_46[0x8] = _mm_mulhi_epi16(xmm5_45, xmm7_23)
    int32_t xmm0_48[0x4] = _mm_adds_epi16(xmm0_47, xmm3_24)
    int32_t xmm6_25[0x4] = _mm_adds_epi16(xmm6_24, xmm4_44)
    int16_t xmm3_25[0x8] = __pmulhw_xmmdq_memdq(xmm3_24, data_78d6d0.o)
    uint16_t xmm0_49[0x8] = xmm0_48 | data_78d6b0.o
    int32_t xmm5_47[0x4] = _mm_adds_epi16(xmm5_46, xmm7_23)
    int32_t xmm7_24[0x4] = _mm_subs_epi16(xmm7_23, xmm6_25)
    *(edx + 0x10) = _mm_shufflehi_epi16(xmm0_49, 0x1b)
    int32_t xmm5_48[0x4] = _mm_adds_epi16(xmm5_47, xmm4_44)
    *(edx + 0x30) = _mm_shufflehi_epi16(xmm7_24, 0x1b)
    int32_t xmm3_26[0x4] = _mm_subs_epi16(xmm3_25, xmm1_56)
    *(edx + 0x50) = _mm_shufflehi_epi16(xmm5_48, 0x1b)
    *(edx + 0x70) = _mm_shufflehi_epi16(xmm3_26, 0x1b)
    
    if (edx == esp)
    label_701a0a:
        int128_t xmm0_51 = *esp
        uint128_t xmm2_24 = xmm0_51 u>> 0x40
        int32_t xmm0_52[0x4] = xmm0_51 | (*(esp + 0x40)).q << 0x40
        int32_t xmm0_53[0x4] = _mm_adds_epi16(xmm0_52, xmm2_24)
        int64_t xmm1_59 = _mm_subs_epi16(xmm0_52, xmm2_24)
        int32_t xmm0_54[0x4] = _mm_unpacklo_epi32(xmm0_53, xmm1_59)
        int32_t xmm4_46[0x4] = _mm_unpackhi_epi32(xmm0_53, xmm1_59)
        uint32_t xmm2_25[0x4] = _mm_shuffle_epi32(xmm0_54, 0x4e)
        uint32_t xmm6_26[0x4] = _mm_shuffle_epi32(xmm4_46, 0x4e)
        int16_t xmm1_61[0x8] = _mm_madd_epi16(data_78d820, xmm0_54)
        int16_t xmm3_29[0x8] = _mm_madd_epi16(data_78d830, xmm2_25)
        int16_t xmm0_55[0x8] = __pmaddwd_xmmdq_memdq(xmm0_54, data_78d840)
        int16_t xmm2_26[0x8] = __pmaddwd_xmmdq_memdq(xmm2_25, data_78d850)
        int32_t xmm1_62[0x4] = __paddd_xmmdq_memdq(xmm1_61, data_78d6c0.o)
        int32_t xmm0_56[0x4] = __paddd_xmmdq_memdq(xmm0_55, data_78d6c0.o)
        int64_t xmm1_65 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_62, xmm3_29), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm0_56, xmm2_26), 0x14))
        int16_t xmm5_51[0x8] = _mm_madd_epi16(data_78d820, xmm4_46)
        int16_t xmm7_27[0x8] = _mm_madd_epi16(data_78d830, xmm6_26)
        int16_t xmm4_47[0x8] = __pmaddwd_xmmdq_memdq(xmm4_46, data_78d840)
        int16_t xmm6_27[0x8] = __pmaddwd_xmmdq_memdq(xmm6_26, data_78d850)
        int32_t xmm5_52[0x4] = __paddd_xmmdq_memdq(xmm5_51, data_78d6c0.o)
        int32_t xmm4_48[0x4] = __paddd_xmmdq_memdq(xmm4_47, data_78d6c0.o)
        int64_t xmm5_55 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_52, xmm7_27), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm4_48, xmm6_27), 0x14))
        *arg1 = xmm1_65
        *(arg1 + 8) = *(arg1 + 8) | xmm1_65 << 0x40
        arg1[4].q = xmm5_55
        *(arg1 + 0x48) = *(arg1 + 0x48) | xmm5_55 << 0x40
        int128_t xmm0_59 = *(esp + 0x10)
        uint128_t xmm2_27 = xmm0_59 u>> 0x40
        int32_t xmm0_60[0x4] = xmm0_59 | (*(esp + 0x70)).q << 0x40
        int32_t xmm0_61[0x4] = _mm_adds_epi16(xmm0_60, xmm2_27)
        int64_t xmm1_68 = _mm_subs_epi16(xmm0_60, xmm2_27)
        int32_t xmm0_62[0x4] = _mm_unpacklo_epi32(xmm0_61, xmm1_68)
        int32_t xmm4_52[0x4] = _mm_unpackhi_epi32(xmm0_61, xmm1_68)
        uint32_t xmm2_28[0x4] = _mm_shuffle_epi32(xmm0_62, 0x4e)
        uint32_t xmm6_28[0x4] = _mm_shuffle_epi32(xmm4_52, 0x4e)
        int16_t xmm1_70[0x8] = _mm_madd_epi16(data_78d860, xmm0_62)
        int16_t xmm3_31[0x8] = _mm_madd_epi16(data_78d870, xmm2_28)
        int16_t xmm0_63[0x8] = __pmaddwd_xmmdq_memdq(xmm0_62, data_78d880)
        int16_t xmm2_29[0x8] = __pmaddwd_xmmdq_memdq(xmm2_28, data_78d890)
        int32_t xmm1_71[0x4] = __paddd_xmmdq_memdq(xmm1_70, data_78d6c0.o)
        int32_t xmm0_64[0x4] = __paddd_xmmdq_memdq(xmm0_63, data_78d6c0.o)
        int64_t xmm1_74 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_71, xmm3_31), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm0_64, xmm2_29), 0x14))
        int16_t xmm5_57[0x8] = _mm_madd_epi16(data_78d860, xmm4_52)
        int16_t xmm7_29[0x8] = _mm_madd_epi16(data_78d870, xmm6_28)
        int16_t xmm4_53[0x8] = __pmaddwd_xmmdq_memdq(xmm4_52, data_78d880)
        int16_t xmm6_29[0x8] = __pmaddwd_xmmdq_memdq(xmm6_28, data_78d890)
        int32_t xmm5_58[0x4] = __paddd_xmmdq_memdq(xmm5_57, data_78d6c0.o)
        int32_t xmm4_54[0x4] = __paddd_xmmdq_memdq(xmm4_53, data_78d6c0.o)
        int64_t xmm5_61 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_58, xmm7_29), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm4_54, xmm6_29), 0x14))
        arg1[1].q = xmm1_74
        *(arg1 + 0x18) = *(arg1 + 0x18) | xmm1_74 << 0x40
        arg1[7].q = xmm5_61
        *(arg1 + 0x78) = *(arg1 + 0x78) | xmm5_61 << 0x40
        int128_t xmm0_67 = *(esp + 0x20)
        uint128_t xmm2_30 = xmm0_67 u>> 0x40
        int32_t xmm0_68[0x4] = xmm0_67 | (*(esp + 0x60)).q << 0x40
        int32_t xmm0_69[0x4] = _mm_adds_epi16(xmm0_68, xmm2_30)
        int64_t xmm1_77 = _mm_subs_epi16(xmm0_68, xmm2_30)
        int32_t xmm0_70[0x4] = _mm_unpacklo_epi32(xmm0_69, xmm1_77)
        int32_t xmm4_58[0x4] = _mm_unpackhi_epi32(xmm0_69, xmm1_77)
        uint32_t xmm2_31[0x4] = _mm_shuffle_epi32(xmm0_70, 0x4e)
        uint32_t xmm6_30[0x4] = _mm_shuffle_epi32(xmm4_58, 0x4e)
        int16_t xmm1_79[0x8] = _mm_madd_epi16(data_78d8a0, xmm0_70)
        int16_t xmm3_33[0x8] = _mm_madd_epi16(data_78d8b0, xmm2_31)
        int16_t xmm0_71[0x8] = __pmaddwd_xmmdq_memdq(xmm0_70, data_78d8c0)
        int16_t xmm2_32[0x8] = __pmaddwd_xmmdq_memdq(xmm2_31, data_78d8d0)
        int32_t xmm1_80[0x4] = __paddd_xmmdq_memdq(xmm1_79, data_78d6c0.o)
        int32_t xmm0_72[0x4] = __paddd_xmmdq_memdq(xmm0_71, data_78d6c0.o)
        int64_t xmm1_83 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_80, xmm3_33), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm0_72, xmm2_32), 0x14))
        int16_t xmm5_63[0x8] = _mm_madd_epi16(data_78d8a0, xmm4_58)
        int16_t xmm7_31[0x8] = _mm_madd_epi16(data_78d8b0, xmm6_30)
        int16_t xmm4_59[0x8] = __pmaddwd_xmmdq_memdq(xmm4_58, data_78d8c0)
        int16_t xmm6_31[0x8] = __pmaddwd_xmmdq_memdq(xmm6_30, data_78d8d0)
        int32_t xmm5_64[0x4] = __paddd_xmmdq_memdq(xmm5_63, data_78d6c0.o)
        int32_t xmm4_60[0x4] = __paddd_xmmdq_memdq(xmm4_59, data_78d6c0.o)
        int64_t xmm5_67 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_64, xmm7_31), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm4_60, xmm6_31), 0x14))
        arg1[2].q = xmm1_83
        *(arg1 + 0x28) = *(arg1 + 0x28) | xmm1_83 << 0x40
        arg1[6].q = xmm5_67
        *(arg1 + 0x68) = *(arg1 + 0x68) | xmm5_67 << 0x40
        int128_t xmm0_75 = *(esp + 0x30)
        uint128_t xmm2_33 = xmm0_75 u>> 0x40
        int32_t xmm0_76[0x4] = xmm0_75 | (*(esp + 0x50)).q << 0x40
        int32_t xmm0_77[0x4] = _mm_adds_epi16(xmm0_76, xmm2_33)
        int64_t xmm1_86 = _mm_subs_epi16(xmm0_76, xmm2_33)
        int32_t xmm0_78[0x4] = _mm_unpacklo_epi32(xmm0_77, xmm1_86)
        int32_t xmm4_64[0x4] = _mm_unpackhi_epi32(xmm0_77, xmm1_86)
        uint32_t xmm2_34[0x4] = _mm_shuffle_epi32(xmm0_78, 0x4e)
        uint32_t xmm6_32[0x4] = _mm_shuffle_epi32(xmm4_64, 0x4e)
        int16_t xmm1_88[0x8] = _mm_madd_epi16(*"BKBKbh~XF", xmm0_78)
        int16_t xmm3_35[0x8] = _mm_madd_epi16(*"BKBK!;", xmm2_34)
        int16_t xmm0_79[0x8] = __pmaddwd_xmmdq_memdq(xmm0_78, data_78d900)
        int16_t xmm2_35[0x8] = __pmaddwd_xmmdq_memdq(xmm2_34, data_78d910)
        int32_t xmm1_89[0x4] = __paddd_xmmdq_memdq(xmm1_88, data_78d6c0.o)
        int32_t xmm0_80[0x4] = __paddd_xmmdq_memdq(xmm0_79, data_78d6c0.o)
        int64_t xmm1_92 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_89, xmm3_35), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm0_80, xmm2_35), 0x14))
        int16_t xmm5_69[0x8] = _mm_madd_epi16(*"BKBKbh~XF", xmm4_64)
        int16_t xmm7_33[0x8] = _mm_madd_epi16(*"BKBK!;", xmm6_32)
        int16_t xmm4_65[0x8] = __pmaddwd_xmmdq_memdq(xmm4_64, data_78d900)
        int16_t xmm6_33[0x8] = __pmaddwd_xmmdq_memdq(xmm6_32, data_78d910)
        int32_t xmm5_70[0x4] = __paddd_xmmdq_memdq(xmm5_69, data_78d6c0.o)
        int32_t xmm4_66[0x4] = __paddd_xmmdq_memdq(xmm4_65, data_78d6c0.o)
        int64_t xmm5_73 = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_70, xmm7_33), 0x14), 
            _mm_srai_epi32(_mm_add_epi32(xmm4_66, xmm6_33), 0x14))
        arg1[3].q = xmm1_92
        *(arg1 + 0x38) = *(arg1 + 0x38) | xmm1_92 << 0x40
        arg1[5].q = xmm5_73
        *(arg1 + 0x58) = *(arg1 + 0x58) | xmm5_73 << 0x40
        return 
else
    int32_t xmm0[0x4] = arg1[1]
    int32_t xmm1[0x4] = arg1[6]
    int32_t xmm3[0x4] = arg1[2]
    int32_t xmm0_1[0x4] = _mm_adds_epi16(xmm0, xmm1)
    int32_t xmm4[0x4] = arg1[5]
    uint16_t xmm0_2[0x8] = _mm_slli_epi16(xmm0_1, 3)
    int32_t xmm5[0x4] = *arg1
    int32_t xmm4_1[0x4] = _mm_adds_epi16(xmm4, xmm3)
    int32_t xmm5_1[0x4] = __paddsw_xmmdq_memdq(xmm5, arg1[7])
    int32_t xmm2_1[0x4] = _mm_subs_epi16(xmm0, xmm1)
    int16_t xmm1_1[0x8] = *"\nj\nj\nj\nj\nj\nj\nj\nj"
    int32_t xmm4_2[0x4] = _mm_slli_epi16(xmm4_1, 3)
    int32_t xmm0_3[0x4] = _mm_subs_epi16(xmm0_2, xmm4_2)
    int32_t xmm7[0x4] = arg1[3]
    int32_t xmm6_1[0x4] = _mm_adds_epi16(xmm0_2, xmm4_2)
    int32_t xmm7_1[0x4] = __paddsw_xmmdq_memdq(xmm7, arg1[4])
    int16_t xmm1_2[0x8] = _mm_mulhi_epi16(xmm1_1, xmm0_3)
    int32_t xmm5_2[0x4] = _mm_subs_epi16(xmm5_1, xmm7_1)
    int32_t xmm4_4[0x4] = _mm_adds_epi16(xmm5_1, xmm7_1)
    int32_t xmm5_3[0x4] = _mm_slli_epi16(xmm5_2, 3)
    int32_t xmm1_3[0x4] = _mm_adds_epi16(xmm1_2, xmm5_3)
    int32_t xmm4_5[0x4] = _mm_slli_epi16(xmm4_4, 3)
    uint16_t xmm1_4[0x8] = xmm1_3 | data_78d6b0.o
    uint16_t xmm2_2[0x8] = _mm_slli_epi16(xmm2_1, 4)
    int16_t xmm5_4[0x8] = __pmulhw_xmmdq_memdq(xmm5_3, *"\nj\nj\nj\nj\nj\nj\nj\nj")
    int32_t xmm3_1[0x4] = __psubsw_xmmdq_memdq(xmm3, arg1[5])
    int32_t xmm4_6[0x4] = _mm_subs_epi16(xmm4_5, xmm6_1)
    *(edx + 0x20) = _mm_shufflehi_epi16(xmm1_4, 0x1b)
    int32_t xmm7_3[0x4] = _mm_adds_epi16(xmm4_5, xmm6_1)
    int32_t xmm1_6[0x4] = arg1[3]
    int32_t xmm3_2[0x4] = _mm_slli_epi16(xmm3_1, 4)
    int32_t xmm1_7[0x4] = __psubsw_xmmdq_memdq(xmm1_6, arg1[4])
    *(edx + 0x40) = _mm_shufflehi_epi16(xmm4_6, 0x1b)
    int16_t xmm2_4[0x8] = __pmulhw_xmmdq_memdq(_mm_adds_epi16(xmm2_2, xmm3_2), data_78d710.o)
    int32_t xmm6_4[0x4] = __pmulhw_xmmdq_memdq(_mm_subs_epi16(xmm2_2, xmm3_2), data_78d710.o)
    uint16_t xmm5_6[0x8] = _mm_subs_epi16(xmm5_4, xmm0_3) | data_78d6b0.o
    uint16_t xmm1_8[0x8] = _mm_slli_epi16(xmm1_7, 3)
    int32_t xmm2_5[0x4] = xmm2_4 | data_78d6b0.o
    int32_t xmm3_3[0x4] = *arg1
    int32_t xmm1_9[0x4] = _mm_adds_epi16(xmm1_8, xmm6_4)
    int32_t xmm3_4[0x4] = __psubsw_xmmdq_memdq(xmm3_3, arg1[7])
    int32_t xmm4_9[0x4] = _mm_subs_epi16(xmm1_8, xmm6_4)
    int16_t xmm0_4[0x8] = data_78d6d0.o
    uint16_t xmm3_5[0x8] = _mm_slli_epi16(xmm3_4, 3)
    int16_t xmm6_5[0x8] = data_78d6f0.o
    int16_t xmm0_5[0x8] = _mm_mulhi_epi16(xmm0_4, xmm1_9)
    *edx = _mm_shufflehi_epi16(xmm7_3, 0x1b)
    int16_t xmm6_6[0x8] = _mm_mulhi_epi16(xmm6_5, xmm4_9)
    *(edx + 0x60) = _mm_shufflehi_epi16(xmm5_6, 0x1b)
    int16_t xmm5_8[0x8] = data_78d6f0.o
    int32_t xmm7_6[0x4] = _mm_subs_epi16(xmm3_5, xmm2_5)
    int32_t xmm3_6[0x4] = _mm_adds_epi16(xmm3_5, xmm2_5)
    int32_t xmm5_9[0x4] = _mm_mulhi_epi16(xmm5_8, xmm7_6)
    int32_t xmm0_6[0x4] = _mm_adds_epi16(xmm0_5, xmm3_6)
    int32_t xmm6_7[0x4] = _mm_adds_epi16(xmm6_6, xmm4_9)
    int16_t xmm3_7[0x8] = __pmulhw_xmmdq_memdq(xmm3_6, data_78d6d0.o)
    uint16_t xmm0_7[0x8] = xmm0_6 | data_78d6b0.o
    int32_t xmm5_10[0x4] = _mm_adds_epi16(xmm5_9, xmm7_6)
    int32_t xmm7_7[0x4] = _mm_subs_epi16(xmm7_6, xmm6_7)
    *(edx + 0x10) = _mm_shufflehi_epi16(xmm0_7, 0x1b)
    int32_t xmm5_11[0x4] = _mm_adds_epi16(xmm5_10, xmm4_9)
    *(edx + 0x30) = _mm_shufflehi_epi16(xmm7_7, 0x1b)
    int32_t xmm3_8[0x4] = _mm_subs_epi16(xmm3_7, xmm1_9)
    *(edx + 0x50) = _mm_shufflehi_epi16(xmm5_11, 0x1b)
    *(edx + 0x70) = _mm_shufflehi_epi16(xmm3_8, 0x1b)
    
    if (edx == esp)
        goto label_701a0a

int128_t xmm0_9 = *edx
uint128_t xmm2_6 = xmm0_9 u>> 0x40
int32_t xmm0_10[0x4] = xmm0_9 | (*(edx + 0x40)).q << 0x40
int32_t xmm0_11[0x4] = _mm_adds_epi16(xmm0_10, xmm2_6)
int64_t xmm1_12 = _mm_subs_epi16(xmm0_10, xmm2_6)
int32_t xmm0_12[0x4] = _mm_unpacklo_epi32(xmm0_11, xmm1_12)
int32_t xmm4_11[0x4] = _mm_unpackhi_epi32(xmm0_11, xmm1_12)
uint32_t xmm2_7[0x4] = _mm_shuffle_epi32(xmm0_12, 0x4e)
uint32_t xmm6_8[0x4] = _mm_shuffle_epi32(xmm4_11, 0x4e)
int16_t xmm1_14[0x8] = _mm_madd_epi16(data_78d820, xmm0_12)
int16_t xmm3_11[0x8] = _mm_madd_epi16(data_78d830, xmm2_7)
int16_t xmm0_13[0x8] = __pmaddwd_xmmdq_memdq(xmm0_12, data_78d840)
int16_t xmm2_8[0x8] = __pmaddwd_xmmdq_memdq(xmm2_7, data_78d850)
int32_t xmm1_15[0x4] = __paddd_xmmdq_memdq(xmm1_14, data_78d6c0.o)
int32_t xmm0_14[0x4] = __paddd_xmmdq_memdq(xmm0_13, data_78d6c0.o)
int32_t xmm1_18[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_15, xmm3_11), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm0_14, xmm2_8), 0x14))
int16_t xmm5_14[0x8] = _mm_madd_epi16(data_78d820, xmm4_11)
int16_t xmm7_10[0x8] = _mm_madd_epi16(data_78d830, xmm6_8)
int16_t xmm4_12[0x8] = __pmaddwd_xmmdq_memdq(xmm4_11, data_78d840)
int16_t xmm6_9[0x8] = __pmaddwd_xmmdq_memdq(xmm6_8, data_78d850)
int32_t xmm5_15[0x4] = __paddd_xmmdq_memdq(xmm5_14, data_78d6c0.o)
int32_t xmm4_13[0x4] = __paddd_xmmdq_memdq(xmm4_12, data_78d6c0.o)
int32_t xmm5_18[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_15, xmm7_10), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm4_13, xmm6_9), 0x14))
*edx = xmm1_18
*(edx + 0x40) = xmm5_18
int128_t xmm0_17 = *(edx + 0x10)
uint128_t xmm2_9 = xmm0_17 u>> 0x40
int32_t xmm0_18[0x4] = xmm0_17 | (*(edx + 0x70)).q << 0x40
int32_t xmm0_19[0x4] = _mm_adds_epi16(xmm0_18, xmm2_9)
int64_t xmm1_21 = _mm_subs_epi16(xmm0_18, xmm2_9)
int32_t xmm0_20[0x4] = _mm_unpacklo_epi32(xmm0_19, xmm1_21)
int32_t xmm4_17[0x4] = _mm_unpackhi_epi32(xmm0_19, xmm1_21)
uint32_t xmm2_10[0x4] = _mm_shuffle_epi32(xmm0_20, 0x4e)
uint32_t xmm6_10[0x4] = _mm_shuffle_epi32(xmm4_17, 0x4e)
int16_t xmm1_23[0x8] = _mm_madd_epi16(data_78d860, xmm0_20)
int16_t xmm3_13[0x8] = _mm_madd_epi16(data_78d870, xmm2_10)
int16_t xmm0_21[0x8] = __pmaddwd_xmmdq_memdq(xmm0_20, data_78d880)
int16_t xmm2_11[0x8] = __pmaddwd_xmmdq_memdq(xmm2_10, data_78d890)
int32_t xmm1_24[0x4] = __paddd_xmmdq_memdq(xmm1_23, data_78d6c0.o)
int32_t xmm0_22[0x4] = __paddd_xmmdq_memdq(xmm0_21, data_78d6c0.o)
int32_t xmm1_27[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_24, xmm3_13), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm0_22, xmm2_11), 0x14))
int16_t xmm5_20[0x8] = _mm_madd_epi16(data_78d860, xmm4_17)
int16_t xmm7_12[0x8] = _mm_madd_epi16(data_78d870, xmm6_10)
int16_t xmm4_18[0x8] = __pmaddwd_xmmdq_memdq(xmm4_17, data_78d880)
int16_t xmm6_11[0x8] = __pmaddwd_xmmdq_memdq(xmm6_10, data_78d890)
int32_t xmm5_21[0x4] = __paddd_xmmdq_memdq(xmm5_20, data_78d6c0.o)
int32_t xmm4_19[0x4] = __paddd_xmmdq_memdq(xmm4_18, data_78d6c0.o)
int32_t xmm5_24[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_21, xmm7_12), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm4_19, xmm6_11), 0x14))
*(edx + 0x10) = xmm1_27
*(edx + 0x70) = xmm5_24
int128_t xmm0_25 = *(edx + 0x20)
uint128_t xmm2_12 = xmm0_25 u>> 0x40
int32_t xmm0_26[0x4] = xmm0_25 | (*(edx + 0x60)).q << 0x40
int32_t xmm0_27[0x4] = _mm_adds_epi16(xmm0_26, xmm2_12)
int64_t xmm1_30 = _mm_subs_epi16(xmm0_26, xmm2_12)
int32_t xmm0_28[0x4] = _mm_unpacklo_epi32(xmm0_27, xmm1_30)
int32_t xmm4_23[0x4] = _mm_unpackhi_epi32(xmm0_27, xmm1_30)
uint32_t xmm2_13[0x4] = _mm_shuffle_epi32(xmm0_28, 0x4e)
uint32_t xmm6_12[0x4] = _mm_shuffle_epi32(xmm4_23, 0x4e)
int16_t xmm1_32[0x8] = _mm_madd_epi16(data_78d8a0, xmm0_28)
int16_t xmm3_15[0x8] = _mm_madd_epi16(data_78d8b0, xmm2_13)
int16_t xmm0_29[0x8] = __pmaddwd_xmmdq_memdq(xmm0_28, data_78d8c0)
int16_t xmm2_14[0x8] = __pmaddwd_xmmdq_memdq(xmm2_13, data_78d8d0)
int32_t xmm1_33[0x4] = __paddd_xmmdq_memdq(xmm1_32, data_78d6c0.o)
int32_t xmm0_30[0x4] = __paddd_xmmdq_memdq(xmm0_29, data_78d6c0.o)
int32_t xmm1_36[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_33, xmm3_15), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm0_30, xmm2_14), 0x14))
int16_t xmm5_26[0x8] = _mm_madd_epi16(data_78d8a0, xmm4_23)
int16_t xmm7_14[0x8] = _mm_madd_epi16(data_78d8b0, xmm6_12)
int16_t xmm4_24[0x8] = __pmaddwd_xmmdq_memdq(xmm4_23, data_78d8c0)
int16_t xmm6_13[0x8] = __pmaddwd_xmmdq_memdq(xmm6_12, data_78d8d0)
int32_t xmm5_27[0x4] = __paddd_xmmdq_memdq(xmm5_26, data_78d6c0.o)
int32_t xmm4_25[0x4] = __paddd_xmmdq_memdq(xmm4_24, data_78d6c0.o)
int32_t xmm5_30[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_27, xmm7_14), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm4_25, xmm6_13), 0x14))
*(edx + 0x20) = xmm1_36
*(edx + 0x60) = xmm5_30
int128_t xmm0_33 = *(edx + 0x30)
uint128_t xmm2_15 = xmm0_33 u>> 0x40
int32_t xmm0_34[0x4] = xmm0_33 | (*(edx + 0x50)).q << 0x40
int32_t xmm0_35[0x4] = _mm_adds_epi16(xmm0_34, xmm2_15)
int64_t xmm1_39 = _mm_subs_epi16(xmm0_34, xmm2_15)
int32_t xmm0_36[0x4] = _mm_unpacklo_epi32(xmm0_35, xmm1_39)
int32_t xmm4_29[0x4] = _mm_unpackhi_epi32(xmm0_35, xmm1_39)
uint32_t xmm2_16[0x4] = _mm_shuffle_epi32(xmm0_36, 0x4e)
uint32_t xmm6_14[0x4] = _mm_shuffle_epi32(xmm4_29, 0x4e)
int16_t xmm1_41[0x8] = _mm_madd_epi16(*"BKBKbh~XF", xmm0_36)
int16_t xmm3_17[0x8] = _mm_madd_epi16(*"BKBK!;", xmm2_16)
int16_t xmm0_37[0x8] = __pmaddwd_xmmdq_memdq(xmm0_36, data_78d900)
int16_t xmm2_17[0x8] = __pmaddwd_xmmdq_memdq(xmm2_16, data_78d910)
int32_t xmm1_42[0x4] = __paddd_xmmdq_memdq(xmm1_41, data_78d6c0.o)
int32_t xmm0_38[0x4] = __paddd_xmmdq_memdq(xmm0_37, data_78d6c0.o)
int32_t xmm1_45[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm1_42, xmm3_17), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm0_38, xmm2_17), 0x14))
int16_t xmm5_32[0x8] = _mm_madd_epi16(*"BKBKbh~XF", xmm4_29)
int16_t xmm7_16[0x8] = _mm_madd_epi16(*"BKBK!;", xmm6_14)
int16_t xmm4_30[0x8] = __pmaddwd_xmmdq_memdq(xmm4_29, data_78d900)
int16_t xmm6_15[0x8] = __pmaddwd_xmmdq_memdq(xmm6_14, data_78d910)
int32_t xmm5_33[0x4] = __paddd_xmmdq_memdq(xmm5_32, data_78d6c0.o)
int32_t xmm4_31[0x4] = __paddd_xmmdq_memdq(xmm4_30, data_78d6c0.o)
int32_t xmm5_36[0x4] = _mm_packs_epi32(_mm_srai_epi32(_mm_add_epi32(xmm5_33, xmm7_16), 0x14), 
    _mm_srai_epi32(_mm_add_epi32(xmm4_31, xmm6_15), 0x14))
*(edx + 0x30) = xmm1_45
*(edx + 0x50) = xmm5_36
